[OpenAI]
#
# OpenAI or Azure OpenAI Service
#

# Default options: openai, azure
API_TYPE=ollama

# Check Azure's documentation for updates here:
# https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-python
AZURE_API_VERSION=2023-05-15

#
# Model parameters
#

MODEL=gpt-4o-mini
MAX_TOKENS=4000
TEMPERATURE=1.5
FREQ_PENALTY=0.3
PRESENCE_PENALTY=0.0
TIMEOUT=60
MAX_ATTEMPTS=5
WAITING_TIME=2
EXPONENTIAL_BACKOFF_FACTOR=5

EMBEDDING_MODEL=text-embedding-3-small 

CACHE_API_CALLS=False
CACHE_FILE_NAME=openai_api_cache.pickle

MAX_CONTENT_DISPLAY_LENGTH=1024

[Simulation]
RAI_HARMFUL_CONTENT_PREVENTION=True
RAI_COPYRIGHT_INFRINGEMENT_PREVENTION=True


[Logging]
LOGLEVEL=INFO
# ERROR
# WARNING
# INFO
# DEBUG

# Ollama Service Setup
[Ollama]
url = http://100.103.46.96:11434
#base_url = http://localhost:11434/api/chat
base_url = http://100.103.46.96:11434/api/chat
#base_url = http://100.121.219.121:11434/api/chat
#model = qwen2.5:14b
#model = qwen2.5:latest 
model = qwen2.5:72b-instruct
#qwen2.5:72b-instruct
#model = qwq:32b
#qwen2.5:7b-instruct
#qwq:32b
temperature = 0.7
top_p = 0.95
timeout = 1200
#embedding_url = http://100.103.46.96:11434/
embedding_url = http://100.121.219.121:11434/
#embedding_url = http://localhost:11434/
embedding_model = bge-m3:latest
quick_model = qwen2.5:32b-instruct